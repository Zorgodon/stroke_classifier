{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c580cf7",
   "metadata": {},
   "source": [
    "# Predictivity analysis\n",
    "After the experiments done in notebook 1 it was decided that we will be using a KNeighbours classifier and splitting our data using the Stratified KFold method in scikit. \n",
    "\n",
    "In this notebook the predictivity of data trained using this model will be analysed and cross validated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0004a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'figure.max_open_warning': 0})\n",
    "from matplotlib.ticker import MaxNLocator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba49157",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(fname: str, cv: str) -> tuple:\n",
    "    \"\"\"Loads data from a CSV file and splits it using scikit\"\"\"\n",
    "\n",
    "    # read data\n",
    "    data = pd.read_csv(fname)\n",
    "    y_column = 'stroke'\n",
    "    X_columns = list(data.columns)\n",
    "    X_columns.remove(y_column)\n",
    "    X = data[X_columns].to_numpy()\n",
    "    y = data[y_column].to_numpy()\n",
    "\n",
    "    # splitting calling the scikit split method of each cross validator\n",
    "    for train_index, test_index in cv.split(X, y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # return all\n",
    "    return X, y, X_train, y_train, X_test, y_test\n",
    "\n",
    "class Regressor:\n",
    "    \"\"\"Sets up regressor with the type of regressor and type of splitting\"\"\"\n",
    "    def __init__(self, cls, fname: str, cv, cls_kwargs: dict = {}, cv_kwargs: dict = {} ):\n",
    "        # construct regressor object\n",
    "        self.regressor = cls(**cls_kwargs)\n",
    "        self.cv = cv(**cv_kwargs)\n",
    "\n",
    "        # use load function\n",
    "        # where cv is a splitting class i.e kFold()\n",
    "        self.X, self.y, self.X_train, self.y_train, self.X_test, self.y_test = load(fname, self.cv)\n",
    "\n",
    "        # fit data\n",
    "        self.regressor.fit(self.X_train, self.y_train)\n",
    "\n",
    "        # get predicted data\n",
    "        self.y_pred = self.regressor.predict(self.X_test)\n",
    "\n",
    "    def metric(self, cls, **kwargs) -> float:\n",
    "        \"\"\"Takes a sklearn.metrics class and returns the score of the regressor object\"\"\"\n",
    "\n",
    "        # use the metric class to get a score\n",
    "        return cls(self.y_test, self.y_pred)\n",
    "    \n",
    "        # method that predicts new y values from new x data\n",
    "    def predict(self, newdata):\n",
    "        \"\"\"returns predicted value from new X data\"\"\"\n",
    "        y = self.regressor.predict(newdata)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb738b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class postplotter:\n",
    "    \n",
    "    #initalise self with regressor object and test data\n",
    "    def __init__ (self, x_test, y_test, y_pred):\n",
    "        self.y_test = y_test\n",
    "        self.y_pred = y_pred\n",
    "        self.x_test = x_test\n",
    "        \n",
    "    # plots confusion matrix and gives FR values\n",
    "        \n",
    "    def confmatrix (self, title: str):\n",
    "    \n",
    "        fig, ax = plt.subplots()\n",
    "        array = np.zeros((2, 2))\n",
    "\n",
    "        for i, correct_value in enumerate(self.y_test):\n",
    "            predicted_value = int(abs(np.round(self.y_pred[i])))\n",
    "            array[predicted_value, correct_value] += 1\n",
    "        \n",
    "\n",
    "\n",
    "        # plot array as image\n",
    "        im = ax.imshow(array, origin='lower', cmap='viridis')\n",
    "\n",
    "        # label axes\n",
    "        ax.set_xlabel('Real Type')\n",
    "        ax.set_ylabel('Predicted Type')\n",
    "\n",
    "        # add colorbar\n",
    "        plt.colorbar(im)\n",
    "        \n",
    "        ax.yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "        ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "        \n",
    "        for i in range(2):\n",
    "            for j in range(2):\n",
    "\n",
    "                # leave colour as white as the default\n",
    "                color = 'black'\n",
    "                if (i == 2 and j != 2):\n",
    "\n",
    "                    # when overdose happened but wasn't predicted, changed colour\n",
    "                    # to red if it is not 0\n",
    "                    if array[i, j] == 0:\n",
    "                        color = 'black'\n",
    "\n",
    "                    else:\n",
    "                        color = 'black'\n",
    "\n",
    "                # set colour to black for the light coloured square\n",
    "                # this is done after plotting once\n",
    "                elif i == 1 and j == 1:\n",
    "                    color = 'black'\n",
    "\n",
    "                # add text with correct colour\n",
    "                ax.text(j, i, array[i, j], ha='center', va='center', color=color)\n",
    "        \n",
    "        #sets axis title\n",
    "        ax.set_title(title, fontsize=15)\n",
    "\n",
    "        \n",
    "        #calculates F1, P and R values\n",
    "        R = (array[1,1]/(array[1,1]+array[1,0]))*100\n",
    "        \n",
    "        if (array[1,1]+array[0,1]) != 0:\n",
    "            P = (array[1,1]/(array[1,1]+array[0,1]))*100\n",
    "            F1 = 2*P*R/(P+R)\n",
    "            confresults = pd.DataFrame({'Precision P': P, 'F-score F1': F1, 'Recall R': R }, index=[0])\n",
    "\n",
    "        else:\n",
    "            confresults = pd.DataFrame({'Precision P': 'N/A', 'F-score F1': 'N/A', 'Recall R': R }, index=[0])\n",
    "            print(\"P and F1 could not be calculated due to 0 total correct guesses\")\n",
    "\n",
    "        print(confresults.to_string(index=False))\n",
    "    \n",
    "    def scorer(self):\n",
    "        \"\"\"creates score attributes of this class for F1, R and P\"\"\"\n",
    "        array = np.zeros((2, 2))\n",
    "\n",
    "        for i, correct_value in enumerate(self.y_test):\n",
    "            predicted_value = int(abs(np.round(self.y_pred[i])))\n",
    "            array[predicted_value, correct_value] += 1\n",
    "        \n",
    "        self.R = (array[1,1]/(array[1,1]+array[1,0]))*100\n",
    "        \n",
    "        if (array[1,1]+array[0,1]) != 0:\n",
    "            self.P = (array[1,1]/(array[1,1]+array[0,1]))*100\n",
    "            self.F1 = 2*self.P*self.R/(self.P+self.R)\n",
    "        else:\n",
    "            print(\"P and F1 could not be calculated due to 0 total correct guesses\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9c8042",
   "metadata": {},
   "source": [
    "## Changing parameters in the classifier\n",
    "In this cell we run the KNeighbours classifier with different parameters to see which give us the best score. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa37a919",
   "metadata": {},
   "outputs": [],
   "source": [
    "#List Hyperparameters that we want to tune.\n",
    "leaf_sizel = list(range(1,30))\n",
    "n_neighborsl = list(range(1,50))\n",
    "pl=[1,2]\n",
    "\n",
    "#file we are going to test the regressor on \n",
    "fname = 'data/splits/split21.csv'\n",
    "#empty dictionary to put the scores and their corresponding kwargs \n",
    "scoredict = {}\n",
    "\n",
    "#for loop that runs the regressor with all the kwargs in our list \n",
    "for size in leaf_sizel:\n",
    "    for n in n_neighborsl: \n",
    "        for i in pl:\n",
    "            loop_kwargs = {'leaf_size': size , 'n_neighbors': n, 'p': i}\n",
    "            knn = Regressor(KNeighborsClassifier, fname, StratifiedKFold, cls_kwargs = loop_kwargs)#initialise regressor\n",
    "            post = postplotter( knn.X_test, knn.y_test, knn.y_pred)#initialise postplotter\n",
    "            post.scorer()#get the scores using scorer class method from postplotter\n",
    "            scoredict[str(loop_kwargs)] = post.F1 #stores results in the dictionary\n",
    "\n",
    "# identifies the highest score and its respective kwargs\n",
    "bestkwargs = max(scoredict, key=scoredict.get)\n",
    "print(bestkwargs)\n",
    "all_values = scoredict. values()\n",
    "max_F1 = max(all_values) \n",
    "print(max_F1)\n",
    "            \n",
    "            \n",
    "###### maybe could do it this way using GridSearchCV\n",
    "\n",
    "# #Create new KNN object\n",
    "# knn = Regressor(KNeighborsClassifier, fname, StratifiedKFold)\n",
    "# knn_2 = knn.regressor\n",
    "# #Use GridSearch\n",
    "# clf = GridSearchCV(knn_2, hyperparameters, cv=10)\n",
    "# #Fit the model\n",
    "# best_model = clf.fit(knn.X_train,knn.y_train)\n",
    "# #Print The value of best Hyperparameters\n",
    "# print('Best leaf_size:', best_model.best_estimator_.get_params()['leaf_size'])\n",
    "# print('Best p:', best_model.best_estimator_.get_params()['p'])\n",
    "# print('Best n_neighbors:', best_model.best_estimator_.get_params()['n_neighbors'])\n",
    "\n",
    "# knn_kwargs = {'n_neighbors' : best_model.best_estimator_.get_params()['n_neighbors'], \n",
    "#               'p' : best_model.best_estimator_.get_params()['p'], \n",
    "#               'leaf_size':best_model.best_estimator_.get_params()['leaf_size']}\n",
    "# print(knn_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93893a98",
   "metadata": {},
   "source": [
    "## Results from the classifier fitted with the best hyper-parameters\n",
    "\n",
    "shown on a confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e823d56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialise a regressor and postplotter to display the results\n",
    "reg = Regressor(KNeighborsClassifier, fname, StratifiedKFold, cls_kwargs = eval(bestkwargs)) \n",
    "plotter = postplotter( reg.X_test, reg.y_test, reg.y_pred)\n",
    "plotter.confmatrix('Optimised \\n hyper-parameters')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b68df9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
