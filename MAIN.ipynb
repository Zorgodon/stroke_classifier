{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21cf342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "%matplotlib nbagg\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation\n",
    "import matplotlib.widgets\n",
    "import seaborn as sns\n",
    "\n",
    "from tkinter import * \n",
    "import tkinter.messagebox \n",
    "\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib.widgets import RadioButtons\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import (TimeSeriesSplit, KFold, ShuffleSplit,\n",
    "                                     StratifiedKFold, GroupShuffleSplit,\n",
    "                                     GroupKFold, StratifiedShuffleSplit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c81a829",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessor:\n",
    "    \n",
    "    # initalise self with data needed to be preproccessed\n",
    "    def __init__ (self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def encode(self, kind: str, c_name):\n",
    "\n",
    "        # update self.data with the appropriate encoder\n",
    "        assert kind in ['onehot', 'label']\n",
    "        self.kind = kind\n",
    "          \n",
    "        # do one hot encoder\n",
    "        if self.kind == 'onehot':\n",
    "            classes = set(self.data[c_name])\n",
    "            for cls in classes:\n",
    "                self.data[cls] = self.data[c_name].apply(lambda x: 1 if x == cls else 0)\n",
    "            del self.data[c_name]\n",
    "            return self.data\n",
    "            \n",
    "        # do label encoder\n",
    "        else:\n",
    "            classes = set(self.data[c_name])\n",
    "            values = {list(classes)[i]: i for i in range(len(classes))}\n",
    "            self.data[c_name] = self.data[c_name].apply(lambda x: values[x])\n",
    "\n",
    "        return self.data\n",
    "    \n",
    "    def scaler(self, kind: str, c_name):\n",
    "        \n",
    "        # update self.data with the appropriate scaler\n",
    "        \n",
    "         # make sure kind is either minmax or standard\n",
    "        assert kind in ['minmax', 'standard']\n",
    "\n",
    "        # start with minmax\n",
    "        if kind == 'minmax':\n",
    "            min_value = min(self.data[c_name])\n",
    "            max_value = max(self.data[c_name])\n",
    "            diff = max_value - min_value\n",
    "            self.data[c_name] = self.data[c_name].apply(lambda x: (x - min_value) / diff)\n",
    "            \n",
    "            return self.data\n",
    "        \n",
    "        # then do standard scaler\n",
    "        else:\n",
    "            mean = self.data[c_name].mean()\n",
    "            std = self.data[c_name].std()\n",
    "            self.data[c_name] = self.data[c_name].apply(lambda x: (x - mean) / std)\n",
    "            \n",
    "        return self.data\n",
    "\n",
    "    # function to remove entire column of data\n",
    "    def remove (self, c_name):\n",
    "        del self.data[c_name]\n",
    "        return self.data\n",
    "     \n",
    "    # function to replace unknown data with mean, median or dropping it\n",
    "    def replace (self, c_name, kind):\n",
    "        assert kind in ['mean', 'median','drop']\n",
    "        \n",
    "        if kind == 'mean':\n",
    "            mean_value = self.data[c_name].mean()\n",
    "            self.data[c_name] = self.data[c_name].fillna(mean_value)\n",
    "            return self.data\n",
    "        \n",
    "        if kind == 'median':\n",
    "            median_value = self.data[c_name].median()\n",
    "            self.data[c_name] = self.data[c_name].fillna(median_value)\n",
    "            return self.data\n",
    "            \n",
    "        else:\n",
    "            self.data = self.data.dropna().reset_index(drop = True)\n",
    "            return self.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb7191a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class preplotter:\n",
    "    \n",
    "    def __init__ (self, data):\n",
    "        self.data = data\n",
    "        \n",
    "    # Function to plot linear 2D or 3D graph takes in column names and output graphs\n",
    "        \n",
    "    # func to plots scatter graphs \n",
    "    # for these functions column names are input, hence by setting the z name to 0 and checking it is not a string\n",
    "    # we can seperate 3D plots from 2D plots\n",
    "    \n",
    "    # for all the functions below, they follow a similar manner\n",
    "    # get fig ax objects\n",
    "    # label axis\n",
    "    # plot graph \n",
    "    \n",
    "    def scatter(self, x_name, y_name, z_name = 0 ):\n",
    "        \n",
    "        # check if data has 3rd dimension\n",
    "        if z_name == 0:\n",
    "            \n",
    "            # gen fig and ax for 2D\n",
    "            fig, ax = plt.subplots()\n",
    "            \n",
    "            # label fig and ax\n",
    "            ax.set_xlabel(x_name)\n",
    "            ax.set_ylabel(y_name)\n",
    "            \n",
    "            # plot data\n",
    "            ax.scatter(self.data[x_name], self.data[y_name], alpha=0.5)\n",
    "        \n",
    "        # generate and for above but in 3D graph\n",
    "        else:\n",
    "            fig = plt.figure()\n",
    "\n",
    "            ax = fig.add_subplot(111, projection='3d')\n",
    "            \n",
    "            # label fig and ax\n",
    "            ax.set_xlabel(x_name)\n",
    "            ax.set_ylabel(y_name)\n",
    "            ax.set_zlabel(z_name)\n",
    "            \n",
    "            # plot data\n",
    "            ax.scatter(self.data[x_name], self.data[y_name], self.data[z_name])    \n",
    "    \n",
    "    # func to plot line graphs same as above\n",
    "    \n",
    "    def line(self, x_name, y_name, z_name = 0):\n",
    "        if z_name == 0:\n",
    "            fig, ax = plt.subplots()\n",
    "            \n",
    "            ax.set_xlabel(x_name)\n",
    "            ax.set_ylabel(y_name)\n",
    "            \n",
    "            ax.plot(self.data[x_name], self.data[y_name])\n",
    "            \n",
    "        else:\n",
    "            fig = plt.figure()\n",
    "\n",
    "            ax = fig.add_subplot(111, projection='3d')\n",
    "            \n",
    "            ax.set_xlabel(x_name)\n",
    "            ax.set_ylabel(y_name)\n",
    "            ax.set_zlabel(z_name)\n",
    "            \n",
    "            ax.plot(self.data[x_name], self.data[y_name], self.data[z_name])\n",
    "            \n",
    "    # plot multiple line plots with radio buttons\n",
    "    \n",
    "    def multiline (self, x_list , y_list, z_list = 0):\n",
    "        \n",
    "        #hard set colours to be used, don't expect more than 8 values to be plotted at once\n",
    "        colours = ('blue', 'green', 'orange', 'red', 'yellow' , 'purple', 'black', 'pink')\n",
    "\n",
    "        # check if input has 3 dimension\n",
    "        if z_list == 0:\n",
    "\n",
    "            # gen fig, ax adjusted for radio buttons\n",
    "            fig, ax = plt.subplots()\n",
    "            plt.subplots_adjust(left=0.45)\n",
    "\n",
    "            # generate empty dictionary\n",
    "            lines = {}\n",
    "            \n",
    "            # generate line dictionary using x_list as keys\n",
    "            for i ,name in enumerate(x_list):\n",
    "\n",
    "                if i == 0:\n",
    "                    lines[name] = ax.plot( self.data[x_list[i]], self.data[y_list[i]], c=colours[i], alpha=0.5)\n",
    "\n",
    "                else:\n",
    "                    lines[name] = ax.plot( self.data[x_list[i]], self.data[y_list[i]], c=colours[i], alpha=0.025)\n",
    "\n",
    "            # create radio box\n",
    "            radio_ax = plt.axes( [0.0, 0.45, 0.3, 0.3],  facecolor='#ffffff')\n",
    "\n",
    "            # create radio buttons\n",
    "            radio = RadioButtons( radio_ax, x_list)\n",
    "\n",
    "            # callback function to run when buttons are pressed\n",
    "            def callback(label: str):\n",
    "                for name, line in lines.items():\n",
    "                    if name == label:\n",
    "                        line[0].set_alpha(0.5)\n",
    "                    else:\n",
    "                        line[0].set_alpha(0.025)\n",
    "                plt.draw()\n",
    "                return\n",
    "\n",
    "            # connect function to radio object and show\n",
    "            radio.on_clicked(callback)\n",
    "\n",
    "            plt.show()\n",
    "\n",
    "            return radio\n",
    "\n",
    "\n",
    "        # if in 3D do simple colour plot\n",
    "        else:\n",
    "            fig = plt.figure()\n",
    "\n",
    "            ax = fig.add_subplot(111, projection='3d')\n",
    "            for i in range(len(x_list)):\n",
    "                ax.plot( self.data[x_list[i]], self.data[y_list[i]], self.data[z_list[i]], label= x_list[i], alpha = 0.5)\n",
    "                plt.legend()\n",
    "\n",
    "\n",
    "    # plot multiple scatter plots do the same as above\n",
    "    \n",
    "    def multiscatter (self, x_list , y_list, z_list = 0):\n",
    "\n",
    "        colours = ('blue', 'green', 'orange', 'red', 'yellow' , 'purple', 'black', 'pink')\n",
    "\n",
    "        if z_list == 0:\n",
    "\n",
    "            fig, ax = plt.subplots()\n",
    "            plt.subplots_adjust(left=0.45)\n",
    "\n",
    "            lines = {}\n",
    "\n",
    "            for i ,name in enumerate(x_list):\n",
    "\n",
    "                if i == 0:\n",
    "                    lines[name] = ax.scatter( self.data[x_list[i]], self.data[y_list[i]], c=colours[i], alpha=0.5)\n",
    "\n",
    "                else:\n",
    "                    lines[name] = ax.scatter( self.data[x_list[i]], self.data[y_list[i]], c=colours[i], alpha=0.025)\n",
    "\n",
    "            # create radio box\n",
    "            radio_ax = plt.axes( [0.0, 0.45, 0.3, 0.3],  facecolor='#ffffff')\n",
    "\n",
    "            # create radio buttons\n",
    "            radio = RadioButtons( radio_ax, x_list)\n",
    "\n",
    "            # callback function to run when buttons are pressed\n",
    "            def callback(label: str):\n",
    "                for name, line in lines.items():\n",
    "                    if name == label:\n",
    "                        line.set_alpha(0.5)\n",
    "                    else:\n",
    "                        line.set_alpha(0.025)\n",
    "                plt.draw()\n",
    "                return\n",
    "\n",
    "            # connect function to radio object and show\n",
    "            radio.on_clicked(callback)\n",
    "\n",
    "            plt.show()\n",
    "\n",
    "            return radio\n",
    "\n",
    "\n",
    "        else:\n",
    "            fig = plt.figure()\n",
    "\n",
    "            ax = fig.add_subplot(111, projection='3d')\n",
    "            for i in range(len(x_list)):\n",
    "                ax.scatter( self.data[x_list[i]], self.data[y_list[i]], self.data[z_list[i]], label= x_list[i], alpha = 0.5)\n",
    "                plt.legend()\n",
    "\n",
    "                \n",
    "    # this function plots a boolean data type's coordination with strokes\n",
    "    def histogram (self, x_list):\n",
    "\n",
    "        # initalise figure and bins\n",
    "        fig, ax = plt.subplots()\n",
    "        bins = [0 ,1]\n",
    "        \n",
    "        # filter data out based on if boolean is 1 or 0\n",
    "        \n",
    "        inter = data[data[x_list] == 1]\n",
    "        # check amount of strokes for bool of 1\n",
    "        strokes = len(inter[inter['stroke'] == 1])\n",
    "        sstrokes = len(inter)\n",
    "        # find % strokes\n",
    "        pstrokes = (strokes/sstrokes)*100\n",
    "        print(f' the percentage of strokes with 1 is {pstrokes}%.')\n",
    "        \n",
    "        # repear with bool of 0\n",
    "        inter2 = data[data[x_list] == 0]\n",
    "        nstrokes = len(inter2[inter2['stroke'] == 1])\n",
    "        snstrokes = len(inter2)\n",
    "        pnstrokes = (nstrokes/snstrokes)*100\n",
    "        print(f' the percentage of strokes with 0 is {pnstrokes}%.')\n",
    "        \n",
    "        # plot these 2 percentage chances against each other and print difference\n",
    "        score = [pnstrokes, pstrokes]\n",
    "        ax.bar(bins,score)\n",
    "        dv = pstrokes - pnstrokes\n",
    "    \n",
    "        print(f'the percentage difference is {dv}%.')\n",
    "        \n",
    "        return dv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ac0d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class postplotter:\n",
    "    \n",
    "    #initalise self with regressor object and test data\n",
    "    def __init__ (self, x_test, y_test, y_pred):\n",
    "        self.y_test = y_test\n",
    "        self.y_pred = y_pred\n",
    "        self.x_test = x_test\n",
    "    # plots real values xy slope = 1 and predicted values variance from that\n",
    "\n",
    "#     def preplot (self):\n",
    "\n",
    "#         fig, ax = plt.subplots()\n",
    "#         ax.plot(self.y_test, self.y_test, 'r-', label='Real')\n",
    "#         ax.scatter(self.y_test, self.y_pred, label = 'prediction')\n",
    "#         ax.set_xlabel('Test Data')\n",
    "#         ax.set_ylabel('Predicted/Test Data')\n",
    "#         ax.legend(frameon=False)\n",
    "#         ax.set_title('Prediction graph')\n",
    "        \n",
    "    # plots confusion matrix and gives FR values\n",
    "        \n",
    "    def confmatrix (self):\n",
    "    \n",
    "#         fig, ax = plt.subplots()\n",
    "        array = np.zeros((2, 2))\n",
    "\n",
    "        for i, correct_value in enumerate(self.y_test):\n",
    "            predicted_value = int(abs(np.round(self.y_pred[i])))\n",
    "            array[predicted_value, correct_value] += 1\n",
    "\n",
    "        # print dataframe represenation of array\n",
    "        print(pd.DataFrame(array))\n",
    "\n",
    "        # plot array as image\n",
    "#         im = ax.imshow(array, origin='lower', cmap='hot_r')\n",
    "\n",
    "#         # label axes\n",
    "#         ax.set_xlabel('Real Type')\n",
    "#         ax.set_ylabel('Predicted Type')\n",
    "\n",
    "#         # add colorbar\n",
    "#         plt.colorbar(im)\n",
    "        \n",
    "        #calculates F1, P and R values\n",
    "        P = (array[1,1]/(array[1,1]+array[0,1]))*100\n",
    "        R = (array[1,1]/(array[1,1]+array[1,0]))*100\n",
    "        F1 = 2*P*R/(P+R)\n",
    "\n",
    "        print(f'Precision is:\\n\\n{P:2f}%\\n')\n",
    "        print(f'recall is:\\n\\n{R:2f}%\\n')\n",
    "        print(f'F-score is:\\n\\n{F1:2f}%\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeafb790",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(fname: str, cv: str) -> tuple:\n",
    "    # basic spliter for now\n",
    "    \"\"\"Loads 2 column data from a CSV file with 2 columns, x and y\"\"\"\n",
    "\n",
    "    # read data\n",
    "    data = pd.read_csv(fname)\n",
    "    y_column = 'stroke'\n",
    "    # get training data\n",
    "    #n_rows = int(len(data) * training_ratio)\n",
    "\n",
    "    X_columns = list(data.columns)\n",
    "    X_columns.remove(y_column)\n",
    "    X = data[X_columns].to_numpy()\n",
    "    y = data[y_column].to_numpy()\n",
    "\n",
    "    # splitting calling the scikit split method of each cross validator\n",
    "    for train_index, test_index in cv.split(X, y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    # return all\n",
    "    return X, y, X_train, y_train, X_test, y_test\n",
    "\n",
    "class Regressor:\n",
    "    \"\"\"Container for analysing different metrics for a single regression class\"\"\"\n",
    "    def __init__(self, cls, fname: str, cv, cls_kwargs: dict = {}, cv_kwargs: dict = {} ):\n",
    "        # construct regressor object\n",
    "        self.regressor = cls(**cls_kwargs)\n",
    "        self.cv = cv(**cv_kwargs)\n",
    "\n",
    "        # use load function\n",
    "        # where cv is a splitting class i.e kFold()\n",
    "        self.X, self.y, self.X_train, self.y_train, self.X_test, self.y_test = load(fname, self.cv)\n",
    "\n",
    "        # fit data\n",
    "        self.regressor.fit(self.X_train, self.y_train)\n",
    "\n",
    "        # get predicted data\n",
    "        self.y_pred = np.round(self.regressor.predict(self.X_test))\n",
    "\n",
    "    def metric(self, cls, **kwargs) -> float:\n",
    "        \"\"\"Takes a sklearn.metrics class and returns the score of the regressor object\"\"\"\n",
    "\n",
    "        # use the metric class to get a score\n",
    "        return cls(self.y_test, self.y_pred)\n",
    "    \n",
    "    def predict(self, newdata):\n",
    "        y = self.regressor.predict(newdata)\n",
    "        return y\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af25ed18",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/healthcare-dataset-stroke-data.csv')\n",
    "# initialise preporcessor class\n",
    "preprocessor = Preprocessor(data.copy())\n",
    "\n",
    "# known id is irrelavent to stroke chance\n",
    "preprocessor.remove('id')\n",
    "\n",
    "# there is enough data to justify dropping NaN values in bmi\n",
    "preprocessor.replace('bmi','drop')\n",
    "\n",
    "# there are only 2 people with other as a gender, as insensitive as this is, they can be dropped\n",
    "preprocessor.encode('onehot','gender')\n",
    "preprocessor.remove(\"Other\")\n",
    "\n",
    "# there are only 2 marriage options, no live in partners or polygamy smh\n",
    "preprocessor.encode('label','ever_married')\n",
    "\n",
    "# more than 2 work tpyes - > onehot\n",
    "preprocessor.encode('onehot','work_type')\n",
    "\n",
    "# there are only 2 residencital types and one is obviously better than the other\n",
    "preprocessor.encode('label','Residence_type')\n",
    "\n",
    "# there are 4 smoking statuses, and the labeling hierarchy makes no sense\n",
    "preprocessor.encode('onehot','smoking_status')\n",
    "\n",
    "# unknown smoking data can be dropped\n",
    "preprocessor.remove('Unknown')\n",
    "\n",
    "# all other data is between 1 and 0 as such to keep all data compareable, we should use minmax scaling as it also keeps\n",
    "# values within 1 and 0\n",
    "preprocessor.scaler('minmax','age')\n",
    "preprocessor.scaler('minmax','avg_glucose_level')\n",
    "preprocessor.scaler('minmax','bmi')\n",
    "# preprocessor.data = preprocessor.data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "#output data to another csv file\n",
    "preprocessor.data.to_csv('data/preprocessed-healthcare-dataset-stroke-data.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26494fab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/preprocessed-healthcare-dataset-stroke-data.csv')\n",
    "\n",
    "# get all keys from datasheet\n",
    "bols = []\n",
    "for key in data.columns:\n",
    "    bols.append(key)\n",
    "\n",
    "# remove non-bools manually, possible for small data set\n",
    "bols.remove('age')\n",
    "bols.remove('avg_glucose_level')\n",
    "bols.remove('bmi')\n",
    "bols.remove('stroke')\n",
    "#bols.remove('never smoked')\n",
    "#bols.remove('Unnamed: 0')\n",
    "\n",
    "# manually set non-bool keys\n",
    "nbols = ['age','avg_glucose_level','bmi', 'smoking']\n",
    "\n",
    "# innitialse class\n",
    "preplots = preplotter(data)\n",
    " \n",
    "#remove_list = ['Unnamed: 0']\n",
    "remove_list = []\n",
    "\n",
    "# look over bool variables\n",
    "for name in bols:\n",
    "    print(name)\n",
    "    # return difference in percentage stroke\n",
    "    dv = preplots.histogram(name)\n",
    "    print('---------------------------------------------------------------------------------------------------------')\n",
    "    # remove data that has similar stroke percentage i.e. non-predictive of stroke chances\n",
    "    if abs(dv) < 1.1 : #ARBITRARY VALUE SET\n",
    "        remove_list.append(name)\n",
    "\n",
    "remove_list.remove('never smoked')\n",
    "\n",
    "print(remove_list)\n",
    "\n",
    "# initalize preprocessor class agaon\n",
    "data_p = Preprocessor(data.copy())\n",
    "# remove 2nd wave of non-predictive data\n",
    "for name in remove_list:\n",
    "    data_p.remove(name)\n",
    "    \n",
    "# save to new file\n",
    "data_p.data.to_csv('data/preprocessed2-healthcare-dataset-stroke-data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6142db4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print scatter graphs for each non-boolean function to check for corrolation\n",
    "for name in nbols:\n",
    "    print(name)\n",
    "    preplots.scatter(name, 'stroke')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7671784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot 3D graphs to check for corrolation\n",
    "preplots.scatter('age','bmi','stroke')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bee97c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using radio buttons we see the different data values\n",
    "preplots.multiscatter(['age','bmi','avg_glucose_level'],['stroke','stroke','stroke'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc121bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cv_indices(cv, X, y, group, ax, n_splits, lw=10):\n",
    "    \"\"\"Create a sample plot for indices of a cross-validation object.\"\"\"\n",
    "    # Generate the training/testing visualizations for each CV split\n",
    "    for ii, (tr, tt) in enumerate(cv.split(X=X, y=y, groups=group)):\n",
    "        # Fill in indices with the training/test groups\n",
    "        indices = np.array([np.nan] * len(X))\n",
    "        indices[tt] = 1\n",
    "        indices[tr] = 0\n",
    "\n",
    "        # Visualize the results\n",
    "        ax.scatter(range(len(indices)), [ii + .5] * len(indices),\n",
    "                   c=indices, marker='_', lw=lw, cmap=cmap_cv,\n",
    "                   vmin=-.2, vmax=1.2)\n",
    "\n",
    "    # Plot the data classes and groups at the end\n",
    "    ax.scatter(range(len(X)), [ii + 1.5] * len(X),\n",
    "               c=y, marker='_', lw=lw, cmap=cmap_data)\n",
    "\n",
    "    ax.scatter(range(len(X)), [ii + 2.5] * len(X),\n",
    "               c=group, marker='_', lw=lw, cmap=cmap_data)\n",
    "\n",
    "    # Formatting\n",
    "    yticklabels = list(range(n_splits)) + ['class', 'group']\n",
    "    ax.set(yticks=np.arange(n_splits+2) + .5, yticklabels=yticklabels,\n",
    "           xlabel='Sample index', ylabel=\"CV iteration\",\n",
    "           ylim=[n_splits+2.2, -.2], xlim=[0, len(y)])\n",
    "    ax.set_title('{}'.format(type(cv).__name__), fontsize=15)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28e94ec",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from matplotlib.patches import Patch\n",
    "#Running different regressors with different splitting techniques and returns the confusion matrix in order\n",
    "#to determine which ones to use for the data \n",
    "reg_list = [LogisticRegression, KNeighborsClassifier, RandomForestRegressor]\n",
    "cv_list = [ShuffleSplit, StratifiedKFold, KFold, RepeatedKFold, StratifiedShuffleSplit]\n",
    "cmap_data = plt.cm.Paired\n",
    "cmap_cv = plt.cm.coolwarm\n",
    "#DEFINE FNAME\n",
    "fname = 'data/preprocessed2-healthcare-dataset-stroke-data.csv'\n",
    "groups_ = data['stroke'].to_numpy()\n",
    "for regressor in reg_list: \n",
    "    for cv in cv_list:\n",
    "        print(f'regressor:{regressor}, splitting:{cv}')\n",
    "        rg = Regressor(regressor, fname, cv)\n",
    "        a = postplotter(rg.X_test, rg.y_test, rg.y_pred)\n",
    "        plotter = pd.DataFrame(rg.X_test)\n",
    "        fig, ax = plt.subplots()\n",
    "        print(rg.y)\n",
    "        plot_cv_indices(rg.cv, rg.X, rg.y, rg.y, ax, rg.cv.get_n_splits() )\n",
    "        ax.legend([Patch(color=cmap_cv(.8)), Patch(color=cmap_cv(.02))],\n",
    "              ['Testing set', 'Training set'], loc=(1.02, .8))\n",
    "\n",
    "        plotter['y_test'] = rg.y_test\n",
    "        plotter['y_pred'] = rg.y_pred\n",
    "#         print(plotter)\n",
    "        a.confmatrix()\n",
    "#         print(rg.y_test)\n",
    "#         print(rg.y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c95e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trying the RandomForestRegressor with different hyper parameters \n",
    "#parameters = np."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22607e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trying the KNN classifier with different hyper parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0087200",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rg = Regressor(regressor, fname, cv)\n",
    "#plot_cv_indices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30de8ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rg = Regressor(RandomForestClassifier, fname, ShuffleSplit, cls_kwargs={'min_samples_leaf' : 1})\n",
    "a = postplotter(rg.X_test, rg.y_test, rg.y_pred)\n",
    "plotter = pd.DataFrame(rg.X_test)\n",
    "fig, ax = plt.subplots()\n",
    "print(rg.y)\n",
    "plot_cv_indices(rg.cv, rg.X, rg.y, rg.y, ax, rg.cv.get_n_splits() )\n",
    "ax.legend([Patch(color=cmap_cv(.8)), Patch(color=cmap_cv(.02))],\n",
    "      ['Testing set', 'Training set'], loc=(1.02, .8))\n",
    "\n",
    "plotter['y_test'] = rg.y_test\n",
    "plotter['y_pred'] = rg.y_pred\n",
    "#print(plotter)\n",
    "a.confmatrix()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7cdbcc8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
